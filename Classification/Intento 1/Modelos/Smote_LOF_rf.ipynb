{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import make_scorer, accuracy_score,roc_auc_score\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1708, 43)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('sinOutliers copy.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        B11       B12       B13       B14       B21       B22       B23  \\\n",
      "0 -0.013263 -0.014149 -0.019776 -0.049727  0.051358  0.054788  0.076576   \n",
      "1 -0.006326 -0.015651 -0.035168 -0.028201  0.014865  0.036778  0.082643   \n",
      "2  0.016539  0.017104  0.041653  0.029021  0.034651  0.035834  0.087266   \n",
      "3 -0.056264 -0.159556 -0.383810 -0.273080  0.011525  0.032684  0.078621   \n",
      "4  0.008978  0.012727  0.023523  0.027729  0.127978  0.181416  0.335318   \n",
      "\n",
      "        B24       B31       B32  ...       B69      B610      B611      B612  \\\n",
      "0  0.192552  0.097446  0.187087  ...  0.297489  1.493572  1.255421  0.399751   \n",
      "1  0.066270  0.554977  0.000000  ...  0.130267  1.714751  0.601136  0.102969   \n",
      "2  0.060801  0.589369  0.000000  ...  0.071542  1.896541  0.738551  0.374806   \n",
      "3  0.055938  0.500754  0.083530  ...  0.440071  1.169690  0.464437  0.275579   \n",
      "4  0.395263  0.458974  0.000000  ...  0.274596  1.777964  0.949099  0.563800   \n",
      "\n",
      "       B613       B81       B82       B83       B84       B85  \n",
      "0  0.016188  0.060745  0.177370  0.017284  0.016202  0.315473  \n",
      "1 -0.098457  0.000052  0.000052  0.000029  0.000012  0.000781  \n",
      "2 -0.117346  0.025741  0.025741  0.015171  0.014670  0.423366  \n",
      "3  0.025202  0.006529  0.007618  0.003815  0.001345  0.116712  \n",
      "4  0.173170  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1703    0\n",
      "1704    0\n",
      "1705    0\n",
      "1706    0\n",
      "1707    0\n",
      "Name: FRACASO, Length: 1708, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varBasuras=['B11','B13','B14','B21','B23','B24','B46','B48',\n",
    "            'B51','B52','B53','B54','B61','B62','B63','B64',\n",
    "            'B65','B66','B67','B611','B85']\n",
    "X=train.drop(columns=varBasuras)\n",
    "X=train.iloc[:,3:]\n",
    "y=train['FRACASO']\n",
    "print(X.head())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy=0.1,random_state=42)\n",
    "X_res,y_res=smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=400,random_state=42,max_depth=3)\n",
    "rf.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>B21</th>\n",
       "      <th>B22</th>\n",
       "      <th>B23</th>\n",
       "      <th>B24</th>\n",
       "      <th>B31</th>\n",
       "      <th>B32</th>\n",
       "      <th>...</th>\n",
       "      <th>B69</th>\n",
       "      <th>B610</th>\n",
       "      <th>B611</th>\n",
       "      <th>B612</th>\n",
       "      <th>B613</th>\n",
       "      <th>B81</th>\n",
       "      <th>B82</th>\n",
       "      <th>B83</th>\n",
       "      <th>B84</th>\n",
       "      <th>B85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>0.788738</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>2.193463</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>0.163583</td>\n",
       "      <td>0.032025</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.033899</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>1.682761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.119959</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.389914</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.789090</td>\n",
       "      <td>0.142155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084605</td>\n",
       "      <td>3.412621</td>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.282370</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.043219</td>\n",
       "      <td>0.051005</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.029681</td>\n",
       "      <td>1.501305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003686</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>-0.014868</td>\n",
       "      <td>-0.012755</td>\n",
       "      <td>0.035654</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>0.123366</td>\n",
       "      <td>0.389314</td>\n",
       "      <td>0.148940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377260</td>\n",
       "      <td>2.945746</td>\n",
       "      <td>1.573920</td>\n",
       "      <td>0.245339</td>\n",
       "      <td>0.092962</td>\n",
       "      <td>0.074470</td>\n",
       "      <td>0.102960</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>0.603646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011324</td>\n",
       "      <td>-0.011484</td>\n",
       "      <td>-0.024643</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>0.047037</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.089339</td>\n",
       "      <td>0.357815</td>\n",
       "      <td>0.176152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.595107</td>\n",
       "      <td>-0.242636</td>\n",
       "      <td>0.562082</td>\n",
       "      <td>0.140930</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.107632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.066137</td>\n",
       "      <td>0.126616</td>\n",
       "      <td>0.257163</td>\n",
       "      <td>0.249419</td>\n",
       "      <td>0.485737</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>1.207386</td>\n",
       "      <td>0.540943</td>\n",
       "      <td>0.487919</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.107180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B11       B12       B13       B14       B21       B22       B23  \\\n",
       "0  0.003355  0.011439  0.055781  0.014390  0.004660  0.015889  0.077480   \n",
       "1  0.006082  0.008248  0.119959  0.008857  0.019770  0.026808  0.389914   \n",
       "2 -0.003686 -0.006865 -0.014868 -0.012755  0.035654  0.066402  0.143807   \n",
       "3 -0.011324 -0.011484 -0.024643 -0.021508  0.047037  0.047704  0.102362   \n",
       "4  0.000486  0.000930  0.001888  0.001831  0.066137  0.126616  0.257163   \n",
       "\n",
       "        B24       B31       B32  ...       B69      B610      B611      B612  \\\n",
       "0  0.019988  0.788738  0.006189  ...  0.059697  2.193463  0.435074  0.163583   \n",
       "1  0.028787  0.789090  0.142155  ...  0.084605  3.412621  0.668726  0.282370   \n",
       "2  0.123366  0.389314  0.148940  ...  0.377260  2.945746  1.573920  0.245339   \n",
       "3  0.089339  0.357815  0.176152  ...  0.029905  0.595107 -0.242636  0.562082   \n",
       "4  0.249419  0.485737  0.021907  ...  0.088596  1.207386  0.540943  0.487919   \n",
       "\n",
       "       B613       B81       B82       B83       B84       B85  \n",
       "0  0.032025  0.033635  0.033899  0.026738  0.007842  1.682761  \n",
       "1  0.070287  0.043219  0.051005  0.040247  0.029681  1.501305  \n",
       "2  0.092962  0.074470  0.102960  0.040084  0.021522  0.603646  \n",
       "3  0.140930  0.098955  0.147670  0.052838  0.052100  1.107632  \n",
       "4  0.107209  0.026733  0.027938  0.013571  0.007089  0.107180  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "test.drop(columns=varBasuras)\n",
    "test=test.iloc[:,1:]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_model is your trained RandomForestClassifier\n",
    "probabilities = rf.predict_proba(test)[:,1]\n",
    "# Convert the NumPy array to a pandas DataFrame\n",
    "probabilities_df = pd.DataFrame(probabilities)\n",
    "probabilities_df.index = probabilities_df.index + 1\n",
    "# Save the DataFrame to a CSV file\n",
    "probabilities_df.to_csv('intento.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
